{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoz8ICnXjylD",
        "outputId": "46053d35-ca07-4b2b-af9a-05deff80542a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "noReg='/content/drive/MyDrive/myProject/Online adversarial attack/model.h5'\n",
        "reg2Link='/content/drive/MyDrive/myProject/Online adversarial attack/MNIST/reg2model.h5' #r2 s=1\n",
        "reg1Link='/content/drive/MyDrive/myProject/Online adversarial attack/MNIST/reg1model.h5'#r1 s=1\n",
        "fmnistLink='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/fmodel.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfhrfN4UTLTV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUlrXa26Ykp2",
        "outputId": "ef4e2776-2391-4f4f-c58f-6e71ccfd0d6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib\n",
        "from tensorflow.python.keras import regularizers\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import InputLayer\n",
        "from IPython.display import clear_output \n",
        "import os\n",
        "import distutils\n",
        "\n",
        "x_train = y_train = x_test = y_test = None\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "epochs = 60\n",
        "epsilon = 2/255\n",
        "success = 0\n",
        "shots = 10\n",
        "alpha = np.exp(-2)\n",
        "stream_length = 10000\n",
        "select = []\n",
        "result = None\n",
        "ground_truth = None\n",
        "vals = []\n",
        "online = None\n",
        "mother_result = None\n",
        "mother_stream = None\n",
        "mother_ground_truth = None\n",
        "mother_flag = False\n",
        "mother_initial_probability = None\n",
        "mother_friendly_probability = None\n",
        "mother_real_loss=None\n",
        "real_loss=None\n",
        "friendly_probability=None\n",
        "initial_probability=None\n",
        "secretary_chosen=[]\n",
        "hard_chosen=[]\n",
        "random_success=[]\n",
        "secretary_success=[]\n",
        "HLGRatio=[]\n",
        "LLGRatio=[]\n",
        "midsuc=0\n",
        "mlg=0\n",
        "fr=[]\n",
        "indices=[]\n",
        "model = None\n",
        "indices = []\n",
        "s = 0\n",
        "classes=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "hard = 0\n",
        "indexMap=[]\n",
        "friendlyTile=2\n",
        "adversarialTile=2\n",
        "reg_strength=1\n",
        "reg_type=\"l2\"\n",
        "\n",
        "if reg_type=='l2':\n",
        "  link=reg2Link\n",
        "\n",
        "elif reg_type=='l1':\n",
        "  link=reg1Link\n",
        "\n",
        "else:\n",
        "  link=None\n",
        "\n",
        "\n",
        "friendlyEpsilon = 0.3\n",
        "reg_loss = None\n",
        "\n",
        "def calcReg(strength,mode='l1'): #other l2\n",
        "  global reg_loss,model\n",
        "  reg_loss=0\n",
        "  \n",
        "  for layer in model.layers:\n",
        "    for temp in layer.weights:\n",
        "      A=np.asarray(temp.numpy())\n",
        "\n",
        "      added=None\n",
        "\n",
        "      if mode=='l1':\n",
        "        added=np.sum(A)\n",
        "\n",
        "      elif mode=='l2':\n",
        "        A=np.power(A,2)\n",
        "        added=np.sum(A)\n",
        "      \n",
        "      else:\n",
        "        raise('error')\n",
        "      \n",
        "      reg_loss=reg_loss+added\n",
        "\n",
        "    \n",
        "    reg_loss=reg_loss*strength\n",
        "    \n",
        "\n",
        "\n",
        "class element:\n",
        "    def __init__(self, i, value):\n",
        "        self.index = i\n",
        "        self.v = value\n",
        "\n",
        "    def __ge__(self, other):\n",
        "        return self.v > other.v\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.v < other.v\n",
        "\n",
        "\n",
        "def testImage(clean_img, adv_image, truth, pred):\n",
        "    plt.imshow(adv_image - clean_img, cmap='gray', vmin=-epsilon, vmax=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def prepareDataset():\n",
        "    global x_train, y_train, x_test, y_test\n",
        "\n",
        "    \n",
        "    if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n",
        "      raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "        \n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    x_train = x_train.astype(\"float32\") / 255\n",
        "    x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "    # add empty color dimension\n",
        "    x_train = np.expand_dims(x_train, -1)\n",
        "    x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "   \n",
        "    b = np.zeros((y_train.size, y_train.max()+1))\n",
        "    b[np.arange(y_train.size),y_train] = 1\n",
        "    y_train=copy.deepcopy(b)\n",
        "\n",
        "    b = np.zeros((y_test.size, y_test.max()+1))\n",
        "    b[np.arange(y_test.size),y_test] = 1\n",
        "    y_test=copy.deepcopy(b)\n",
        "\n",
        "    print(\"x_train\",x_train.shape)\n",
        "    print(\"y_train\",y_train.shape)\n",
        "    print(\"x_test\",x_test.shape)\n",
        "    print(\"y_test\",y_test.shape)\n",
        "\n",
        "\n",
        "def defineModel():\n",
        "    global model\n",
        "    reg=None\n",
        "\n",
        "    if reg_type=='l1':\n",
        "      reg=l1(reg_strength)\n",
        "\n",
        "    elif reg_type=='l2':\n",
        "      reg=l2(reg_strength)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=input_shape))\n",
        "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",kernel_regularizer=reg))\n",
        "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",kernel_regularizer=reg))\n",
        "    model.add(layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",kernel_regularizer=reg))\n",
        "    model.add(layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\",kernel_regularizer=reg))\n",
        "\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Dense(128, activation=\"relu\",kernel_regularizer=reg))\n",
        "    model.add(layers.Dropout(0.55))\n",
        "    model.add(layers.Dense(num_classes, activation=\"softmax\",kernel_regularizer=reg))\n",
        "    model.build()\n",
        "\n",
        "\n",
        "def trainModel():\n",
        "    global model\n",
        "\n",
        "  \n",
        "    saveLink='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST'\n",
        "    model.load_weights(fmnistLink)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    model.save('/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/Fashion-MNIST.h5')\n",
        "    calcReg(reg_strength,reg_type)\n",
        "    print(reg_loss,'reg_loss')          \n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def perturb_vect(mode): # other possible mode : friendly,duo. duo is used for speed up and epsilon is used as friendlyEpsilon\n",
        "  global highest_perturbation,lowest_perturbation\n",
        "  arr=[]\n",
        "  label=[]\n",
        "\n",
        "\n",
        "  for i in range(10000):\n",
        "    arr.append(x_test[i])\n",
        "    label.append(y_test[i])\n",
        "  \n",
        "  arr=np.asarray(arr)\n",
        "  label=np.asarray(label)\n",
        "\n",
        "  length=10000\n",
        "\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "  perturbation=np.zeros((10000,28,28,1))\n",
        "\n",
        "\n",
        "  highest_loss_found=np.zeros((10000))\n",
        "  lowest_loss_found=np.ones((10000))*1000\n",
        " \n",
        "\n",
        "  if mode=='adversarial':\n",
        "    highest_perturbation=np.zeros_like(perturbation)\n",
        "    num=int(28/adversarialTile)\n",
        "    tile=adversarialTile\n",
        "    for layer in range(1):\n",
        "      for i in range(num):\n",
        "        for j in range(num):\n",
        "          print(mode,i,j)\n",
        "          plus=copy.deepcopy(arr)\n",
        "          minus=copy.deepcopy(arr)\n",
        "\n",
        "          plus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=  plus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]+epsilon\n",
        "          minus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=  minus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]-epsilon\n",
        "\n",
        "          plus=model(plus)\n",
        "          minus=model(minus)\n",
        "          \n",
        "    \n",
        "         \n",
        "          plus=cce(label,plus).numpy()\n",
        "          minus=cce(label,minus).numpy()\n",
        "          gt=np.squeeze(np.argwhere(plus>minus))\n",
        "          lt=np.squeeze(np.argwhere(plus<=minus))\n",
        "\n",
        "          perturbation[gt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=epsilon\n",
        "          arr[gt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]+=epsilon\n",
        "\n",
        "          perturbation[lt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=-epsilon\n",
        "          arr[lt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]-=epsilon\n",
        "\n",
        "          gt=np.squeeze(np.argwhere(plus>highest_loss_found))\n",
        "          lt=np.squeeze(np.argwhere(minus>highest_loss_found))\n",
        "\n",
        "          highest_loss_found[gt]=plus[gt]\n",
        "          highest_loss_found[lt]=minus[lt]\n",
        "\n",
        "          highest_perturbation[gt,:,:,:]=perturbation[gt,:,:,:]\n",
        "          highest_perturbation[lt,:,:,:]=perturbation[lt,:,:,:]\n",
        "\n",
        "    return highest_perturbation\n",
        "\n",
        "  elif mode=='friendly':\n",
        "    num=int(28/friendlyTile)\n",
        "    lowest_perturbation=np.zeros_like(perturbation)\n",
        "    tile=friendlyTile\n",
        "    for layer in range(1):\n",
        "      for i in range(num):\n",
        "        for j in range(num):\n",
        "          print(mode,i,j)\n",
        "          plus=copy.deepcopy(arr)\n",
        "          minus=copy.deepcopy(arr)\n",
        "\n",
        "       \n",
        "          plus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=  plus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]+friendlyEpsilon\n",
        "          minus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=  minus[:,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]-friendlyEpsilon\n",
        "\n",
        "          plus=model(plus)\n",
        "          minus=model(minus)\n",
        "          \n",
        "    \n",
        "         \n",
        "          plus=cce(label,plus).numpy()\n",
        "          minus=cce(label,minus).numpy()\n",
        "          gt=np.squeeze(np.argwhere(plus<minus))\n",
        "          lt=np.squeeze(np.argwhere(plus>=minus))\n",
        "\n",
        "          perturbation[gt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=friendlyEpsilon\n",
        "          arr[gt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]+=friendlyEpsilon\n",
        "\n",
        "          perturbation[lt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]=-friendlyEpsilon\n",
        "          arr[lt,i*tile:(i+1)*tile , j*tile:(j+1)*tile,0]-=friendlyEpsilon\n",
        "\n",
        "          gt=np.squeeze(np.argwhere(plus<lowest_loss_found))\n",
        "          lt=np.squeeze(np.argwhere(minus<lowest_loss_found))\n",
        "\n",
        "          lowest_loss_found[gt]=plus[gt]\n",
        "          lowest_loss_found[lt]=minus[lt]\n",
        "\n",
        "          lowest_perturbation[gt,:,:,:]=perturbation[gt,:,:,:]\n",
        "          lowest_perturbation[lt,:,:,:]=perturbation[lt,:,:,:]\n",
        "\n",
        "    return lowest_perturbation\n",
        "\n",
        "  else:\n",
        "    raise('error. invalid mode')\n",
        "\n",
        "\n",
        "def evalModel():\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "\n",
        "  # other possible mode : friendly\n",
        "def perturb_one(idx,mode='adversarial'): # other possible mode : friendly,duo. duo is used for speed up and epsilon is used as friendlyEpsilon\n",
        "\n",
        "  y=np.expand_dims(y_test[idx],axis=0)\n",
        "  temp=np.squeeze(x_test[idx])\n",
        "  x=copy.deepcopy(temp)\n",
        "  highest_loss_found=None\n",
        "  lowest_loss_found=None\n",
        "  highest_perturbation=None\n",
        "  lowest_perturbation=None\n",
        "\n",
        "  \n",
        "\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "  perturbation=np.zeros((28,28))\n",
        "  num=int(28/tile)\n",
        "\n",
        "  if mode=='adversarial':\n",
        "\n",
        "    for i in range(num):\n",
        "      for j in range(num):\n",
        "        plus=copy.deepcopy(x)\n",
        "        minus=copy.deepcopy(x)\n",
        "\n",
        "        plus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=  plus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]+epsilon\n",
        "        minus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=  minus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]-epsilon\n",
        "\n",
        "\n",
        "        plus=np.expand_dims(plus,axis=(0,-1))\n",
        "        minus=np.expand_dims(minus,axis=(0,-1))\n",
        "        plus=model(plus)\n",
        "        minus=model(minus)\n",
        "        plus=cce(y,plus).numpy()\n",
        "        minus=cce(y,minus).numpy()\n",
        "        \n",
        "        if plus>minus:\n",
        "          perturbation[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=epsilon\n",
        "          x[i*tile:(i+1)*tile , j*tile:(j+1)*tile]+=epsilon\n",
        "\n",
        "          if highest_loss_found==None or plus>highest_loss_found:\n",
        "            highest_loss_found=plus\n",
        "            highest_perturbation=copy.deepcopy(perturbation)\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "          perturbation[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=-epsilon\n",
        "          x[i*tile:(i+1)*tile , j*tile:(j+1)*tile]-=epsilon\n",
        "\n",
        "          if highest_loss_found==None or minus>highest_loss_found:\n",
        "              highest_loss_found=minus\n",
        "              highest_perturbation=copy.deepcopy(perturbation)\n",
        "              \n",
        "\n",
        "    return highest_perturbation\n",
        "\n",
        "\n",
        "\n",
        "  elif mode=='friendly':\n",
        "\n",
        "    for i in range(num):\n",
        "      for j in range(num):\n",
        "        plus=copy.deepcopy(x)\n",
        "        minus=copy.deepcopy(x)\n",
        "\n",
        "        plus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=  plus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]+friendlyEpsilon\n",
        "        minus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=  minus[i*tile:(i+1)*tile , j*tile:(j+1)*tile]-friendlyEpsilon\n",
        "\n",
        "\n",
        "        plus=np.expand_dims(plus,axis=(0,-1))\n",
        "        minus=np.expand_dims(minus,axis=(0,-1))\n",
        "        plus=model(plus)\n",
        "        minus=model(minus)\n",
        "        plus=cce(y,plus).numpy()\n",
        "        minus=cce(y,minus).numpy()\n",
        "        \n",
        "        if plus>minus:\n",
        "          perturbation[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=-friendlyEpsilon\n",
        "          x[i*tile:(i+1)*tile , j*tile:(j+1)*tile]-=friendlyEpsilon\n",
        "\n",
        "          if lowest_loss_found==None or minus<lowest_loss_found:\n",
        "            lowest_loss_found=minus\n",
        "            lowest_perturbation=copy.deepcopy(perturbation)\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "          perturbation[i*tile:(i+1)*tile , j*tile:(j+1)*tile]=friendlyEpsilon\n",
        "          x[i*tile:(i+1)*tile , j*tile:(j+1)*tile]+=friendlyEpsilon\n",
        "\n",
        "          if lowest_loss_found==None or plus<lowest_loss_found:\n",
        "              lowest_loss_found=plus\n",
        "              lowest_perturbation=copy.deepcopy(perturbation)\n",
        "\n",
        "    return lowest_perturbation\n",
        "\n",
        "\n",
        "  else:\n",
        "      raise Exception(\"invalid mode\")\n",
        "      \n",
        "\n",
        "def assess(index, metric=\"Loss\"):\n",
        "    global success\n",
        "    x = np.expand_dims(x_test[index], axis=0)\n",
        "    y_expanded = np.expand_dims(y_test[index], axis=0)\n",
        "\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    y=model(x)\n",
        "    initLoss= cce(y_expanded, y)\n",
        "\n",
        "\n",
        "    perturbation = perturb(index,'adversarial')\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xp = x + perturbation\n",
        "    perturbation = perturb(index,'friendly')\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xf = x + perturbation\n",
        "    yf = model(xf)\n",
        "    y = model(xp)\n",
        "    pr = np.argmax(y)\n",
        "    successed = True\n",
        "\n",
        "\n",
        "    if pr == np.argmax(y_test[index]):\n",
        "        successed = False\n",
        "    loss = cce(y_expanded, y)\n",
        "    friendlyLoss=cce(y_expanded, yf)\n",
        "    return (loss+reg_loss, successed, initLoss+reg_loss,friendlyLoss+reg_loss,loss)#friendlyLoss+reg_loss\n",
        "\n",
        "\n",
        "def generate_stream_data(load):\n",
        "    global result, ground_truth, mother_result,mistake, mother_stream, mother_ground_truth, mother_flag, mother_initial_probability, mother_friendly_probability,friendly_probability,initial_probability\n",
        "    global mother_real_loss,real_loss,defsuc,deffail,midsuc,mlg,stream_length,lowest_perturbation,highest_perturbation,indexMap,arr\n",
        "\n",
        "    lower = 0.6931471824645996\n",
        "    upper = 2.3025851249694824\n",
        "\n",
        "    defsuc = 0\n",
        "    midsuc=0\n",
        "    deffail = 0\n",
        "\n",
        "    if mother_flag == False:\n",
        "\n",
        "      mother_flag = True\n",
        "      arr=[]\n",
        "      label=[]\n",
        " \n",
        "      if load==False:\n",
        "\n",
        "\n",
        "        highest_perturbation=perturb_vect('adversarial')\n",
        "\n",
        "        sl='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/highest_pert_'+str(adversarialTile)+'_'+str(epsilon)\n",
        "        np.save(sl,highest_perturbation) \n",
        "\n",
        "        lowLink='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/lowest_pert_'+str(friendlyTile)+'_'+str(friendlyEpsilon)+'.npy'\n",
        "        lowest_perturbation=np.load(lowLink)\n",
        "\n",
        "      \n",
        "\n",
        "         \n",
        "      elif load==True:\n",
        "        lowLink='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/lowest_pert_'+str(friendlyTile)+'_'+str(friendlyEpsilon)+'.npy'\n",
        "        highLink='/content/drive/MyDrive/myProject/Online adversarial attack/FMNIST/highest_pert_'+str(adversarialTile)+'_'+str(epsilon)+'.npy'\n",
        "\n",
        "        lowest_perturbation=np.load(lowLink)\n",
        "        highest_perturbation=np.load(highLink)\n",
        "\n",
        "\n",
        "       \n",
        "       \n",
        "\n",
        "        lowest_perturbation=np.expand_dims(lowest_perturbation,axis=(-1))\n",
        "        highest_perturbation=np.expand_dims(highest_perturbation,axis=(-1))\n",
        "\n",
        "      \n",
        "      for i in range(10000):\n",
        "        arr.append(x_test[i])\n",
        "        label.append(y_test[i])\n",
        "        indexMap.append(i)\n",
        "      \n",
        "\n",
        "      indexMap=np.asarray(indexMap)\n",
        "      arr=np.asarray(arr)\n",
        "      label=np.asarray(label)\n",
        "    \n",
        "      init=model(arr)\n",
        "      mistake=np.not_equal(np.argmax(label,axis=(1)), np.argmax(init,axis=(1)))\n",
        "      mistake=np.where(mistake)\n",
        "   \n",
        "\n",
        "      cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "     \n",
        "\n",
        "\n",
        "      arr=np.delete(arr,mistake,axis=(0))\n",
        "      label=np.delete(label,mistake,axis=(0))\n",
        "      \n",
        "      indexMap=np.delete(indexMap,mistake,axis=(0))\n",
        "\n",
        "      mother_initial_probability=(cce(label,model(arr))+reg_loss).numpy()\n",
        "      lowest_perturbation=np.delete(lowest_perturbation,mistake,axis=(0))\n",
        "      highest_perturbation=np.delete(highest_perturbation,mistake,axis=(0))\n",
        "\n",
        "\n",
        "      lowest_perturbation=np.squeeze(lowest_perturbation)\n",
        "      lowest_perturbation=np.expand_dims(lowest_perturbation,axis=(-1))\n",
        "\n",
        "      highest_perturbation=np.squeeze(highest_perturbation)\n",
        "      highest_perturbation=np.expand_dims(highest_perturbation,axis=(-1))\n",
        "\n",
        "\n",
        "      lowest_perturbation=arr+lowest_perturbation\n",
        "      highest_perturbation=arr+highest_perturbation\n",
        "\n",
        "     \n",
        "\n",
        "      predict=model(highest_perturbation)\n",
        "\n",
        "      mother_ground_truth=(cce(label,model(highest_perturbation))+reg_loss).numpy()\n",
        "      mother_result=np.not_equal(np.argmax(label,axis=(1)), np.argmax(predict,axis=(1)))\n",
        "      mother_friendly_probability=(cce(label,model(lowest_perturbation))+reg_loss).numpy()\n",
        "      mother_real_loss= (mother_ground_truth-reg_loss)\n",
        "\n",
        "      # print(highest_perturbation.shape)\n",
        "      # print(mother_ground_truth.sahpe)\n",
        "      # print(mother_result.shape)\n",
        "      # print(mother_friendly_probability.shape)\n",
        "      # print(mother_real_loss.shape)\n",
        "\n",
        "\n",
        "\n",
        "      lower=0.6931471824645996\n",
        "      upper=2.3025851249694824\n",
        "\n",
        "      for i in range(mother_real_loss.shape[0]):\n",
        "        if mother_real_loss[i]>upper:\n",
        "          defsuc+=1\n",
        "        \n",
        "        if mother_real_loss[i] <lower:\n",
        "          deffail+=1\n",
        "\n",
        "        \n",
        "        if mother_real_loss[i]>=lower and mother_real_loss[i]<=upper:\n",
        "          mlg+=1\n",
        "\n",
        "          if mother_result[i]:\n",
        "            midsuc+=1\n",
        "      \n",
        "      print(\"defsuc: \",defsuc)\n",
        "      print(\"deffail: \",deffail)\n",
        "      print(\"mlg: \",mlg)\n",
        "      print(\"midsuc: \",midsuc)\n",
        "\n",
        "      if not (load==True or load==False):\n",
        "        raise('invalid generation mode')\n",
        "    \n",
        "    idx = np.random.permutation(np.arange(mother_ground_truth.shape[0]))\n",
        "\n",
        "    result = mother_result[idx]\n",
        "    ground_truth = mother_ground_truth[idx]\n",
        "    friendly_probability=mother_friendly_probability[idx]\n",
        "    initial_probability=mother_initial_probability[idx]\n",
        "    real_loss=mother_real_loss[idx]\n",
        "\n",
        "\n",
        "def onlineAttack(verbose=False):\n",
        "  global ground_truth,vals,s,indices,hard,initial_probability,friendly_probability,stream_length\n",
        "  t=int(alpha*stream_length)\n",
        "  R=[]\n",
        "  choosen_sum=0\n",
        "  indices=[]\n",
        "  vals=[]\n",
        "  hard=0\n",
        "\n",
        "  lower=0.6931471824645996\n",
        "  upper=2.3025851249694824\n",
        "  remainedShots=shots\n",
        "  best_estimated_regularization=1000000\n",
        "  stream_length=mother_ground_truth.shape[0]\n",
        "\n",
        "\n",
        "  for i in range(stream_length):\n",
        "      best_estimated_regularization=min(friendly_probability[i],initial_probability[i],best_estimated_regularization)  \n",
        "      ground_truth[i]=ground_truth[i]-best_estimated_regularization\n",
        "\n",
        "    \n",
        "\n",
        "      if verbose:\n",
        "        print(\"best estimation : \",best_estimated_regularization,\" current friendly loss : \",friendly_probability[i],\" current ce loss : \",ground_truth[i],\" init probability : \",initial_probability[i],\"real loss : \",real_loss[i])\n",
        "  \n",
        "\n",
        "  for i in range (t):\n",
        "    if len(indices)>=shots:\n",
        "      break\n",
        "    if ground_truth[i]<lower:\n",
        "\n",
        "      continue\n",
        "    if ground_truth[i]>upper:\n",
        "      hard+=1\n",
        "      remainedShots-=1\n",
        "      indices.append(i)\n",
        "\n",
        "      while len(R)>remainedShots:\n",
        "        R.pop(0)\n",
        "        \n",
        "        \n",
        "\n",
        "      continue\n",
        "\n",
        "    if len(R)<remainedShots:\n",
        "      R.append(ground_truth[i])\n",
        "\n",
        "    elif len(R)==remainedShots:\n",
        "      R.sort()\n",
        "\n",
        "    else:\n",
        "      if ground_truth[i]>R[0]:\n",
        "        R[0]=ground_truth[i]\n",
        "        R.sort()\n",
        "  \n",
        "\n",
        "  for i in range(t,stream_length):\n",
        "    if len(indices)>=shots:\n",
        "      break\n",
        "\n",
        "    if ground_truth[i]<lower:\n",
        "      continue\n",
        "\n",
        "    if ground_truth[i]>upper: \n",
        "      indices.append(i)\n",
        "      remainedShots-=1\n",
        "      hard+=1\n",
        "      while len(R)>remainedShots and len(R)>0:\n",
        "        R.pop(0)\n",
        "        (\"pre len(R)=\",len(R),\"len(indices):\",len(indices))\n",
        "      continue\n",
        "\n",
        "   \n",
        "    if len(R)>0 and ground_truth[i]>R[0]:\n",
        "      indices.append(i)\n",
        "\n",
        "      if len(R)==remainedShots:\n",
        "        R[0]=copy.deepcopy(ground_truth[i])\n",
        "\n",
        "      else:\n",
        "        R.append(copy.deepcopy(ground_truth[i]))\n",
        "        \n",
        "      choosen_sum+=R[0]\n",
        "      vals.append(copy.deepcopy(R[0]))\n",
        "      R.sort()\n",
        "      continue\n",
        "\n",
        "    if len(R)==0:\n",
        "      indices.append(i)\n",
        "      R.append(copy.deepcopy(ground_truth[i]))\n",
        "      choosen_sum+=R[0]\n",
        "      vals.append(copy.deepcopy(R[0]))\n",
        "\n",
        "\n",
        "    \n",
        "    if stream_length-i == shots - len(indices):\n",
        "      for j in range (i,stream_length):\n",
        "        if ground_truth[j]<lower:\n",
        "          continue\n",
        "        indices.append(j)\n",
        "        vals.append(copy.deepcopy(ground_truth[j]))\n",
        "        choosen_sum+=ground_truth[j]\n",
        "      break\n",
        "\n",
        "  s=0\n",
        "\n",
        "  for i in indices:\n",
        "    if result[i]:\n",
        "      s+=1\n",
        "  \n",
        "\n",
        "  hard_chosen.append(hard)\n",
        "  secretary_chosen.append(len(indices)-hard)\n",
        "  \n",
        "  fr.append(s/shots)\n",
        "\n",
        "\n",
        "fool_rate=[]\n",
        "success_avg=[]\n",
        "success_std=[]\n",
        "fail_avg=[]\n",
        "fail_std=[]\n",
        "total_avg=[]\n",
        "total_std=[] \n",
        "\n",
        "\n",
        "\n",
        "def plot(show=False):\n",
        "  global result,ground_truth,vals,hard,indices,hard_chosen,secretary_chosen,secretary_success,fr,real_loss,HLGRatio,MLGRatio\n",
        "  lower=0.6931471824645996\n",
        "  upper=2.3025851249694824\n",
        "  mlg_success=0\n",
        "\n",
        "  for i in indices:\n",
        "   \n",
        "  \n",
        "    if ground_truth[i]<= upper and ground_truth[i]>=lower and result[i] :\n",
        "      mlg_success+=1\n",
        "\n",
        "  if secretary_chosen[-1]>0:\n",
        "    secretary_success.append(mlg_success/secretary_chosen[-1])\n",
        "\n",
        "  mysuc=0\n",
        "  myfail=0\n",
        "\n",
        "  for i in range(stream_length):\n",
        "    if ground_truth[i]>=upper:\n",
        "      mysuc+=1\n",
        "    \n",
        "    if ground_truth[i]<=lower:\n",
        "      myfail+=1\n",
        "\n",
        "  HLGRatio.append(mysuc)\n",
        "  LLGRatio.append(myfail)\n",
        "      \n",
        "\n",
        "\n",
        "def randomSelectionInMLG():\n",
        "  mlg=0\n",
        "  success=0\n",
        "  lower=0.6931471824645996\n",
        "  upper=2.3025851249694824\n",
        "\n",
        "  for i in range(stream_length):\n",
        "     if ground_truth[i]-reg_loss<= upper and ground_truth[i]>=lower:\n",
        "       mlg+=1\n",
        "\n",
        "       if result[i]:\n",
        "         success+=1\n",
        "  \n",
        "  return success/mlg\n",
        "\n",
        "\n",
        "def randomSelectionNotKnowingM():\n",
        "  total=0\n",
        "  success=0\n",
        "  lower=0.6931471824645996\n",
        "  upper=2.3025851249694824\n",
        "\n",
        "  for i in range(stream_length):\n",
        "     if ground_truth[i]>=lower:\n",
        "       total+=1\n",
        "       \n",
        "       if result[i]:\n",
        "         success+=1\n",
        "\n",
        "\n",
        "  return success/total\n",
        "\n",
        "\n",
        "#########################################################################################################################\n",
        "pepareDataset()\n",
        "defineModel()\n",
        "trainModel()\n",
        "evalModel()\n",
        "generate_stream_data(True)\n",
        "onlineAttack()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train (60000, 28, 28, 1)\n",
            "y_train (60000, 10)\n",
            "x_test (10000, 28, 28, 1)\n",
            "y_test (10000, 10)\n",
            "1080.0961165730841 reg_loss\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 24, 24, 32)        18464     \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 22, 22, 16)        4624      \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 20, 20, 8)         1160      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               409728    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 435,906\n",
            "Trainable params: 435,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss: 1080.005126953125\n",
            "Test accuracy: 0.9176999926567078\n",
            "defsuc:  273\n",
            "deffail:  7693\n",
            "mlg:  1211\n",
            "midsuc:  1113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJB4S2J9hZtC",
        "outputId": "bbb24b4d-63ef-4dcd-c214-62e70fbee45b"
      },
      "source": [
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "shots=10\n",
        "iter=1000\n",
        "\n",
        "\n",
        "for i in range(iter):\n",
        "  if i%100==0:\n",
        "    print(i)\n",
        "    \n",
        "  generate_stream_data(True)\n",
        "  onlineAttack()\n",
        "  plot()\n",
        "\n",
        "\n",
        "generate_stream_data(True)\n",
        "# onlineAttack(True)\n",
        "\n",
        "fr=np.asarray(fr, dtype=np.float32)\n",
        "secretary_success=np.asarray(secretary_success, dtype=np.float32)\n",
        "\n",
        "secretary_chosen=np.asarray(secretary_chosen, dtype=np.float32)\n",
        "hard_chosen=np.asarray(hard_chosen, dtype=np.float32)\n",
        "\n",
        "print(\"These are general results yielded for \",iter,\" number of random permutations\")\n",
        "print(\"average fool rate under my assumption : \",np.mean(fr),np.std(fr))\n",
        "\n",
        "print(\"average success for secretary chosen data : \",np.mean(secretary_success),np.std(secretary_success))\n",
        "print(\"average number of data chosen by secretary : \",np.mean(secretary_chosen),np.std(secretary_chosen))\n",
        "print(\"average number of hard chosen data : \",np.mean(hard_chosen),np.std(hard_chosen))\n",
        "print(\"average number of selected data : \",np.mean(hard_chosen+secretary_chosen),np.std(hard_chosen+secretary_chosen))\n",
        "print(\"random choice not knowing m success rate : \",randomSelectionNotKnowingM())\n",
        "print(\"mean HLG grouped : \",np.mean(np.asarray(HLGRatio)))\n",
        "print(\"mean LLG grouped : \",np.mean(np.asarray(LLGRatio)))\n",
        "\n",
        "\n",
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "\n",
        "\n",
        "print(np.amax(mother_friendly_probability))\n",
        "print(np.amax(mother_initial_probability))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plotShots():\n",
        "  \n",
        "  for i in indices:\n",
        "    x= np.expand_dims(x_test[i], axis=0)\n",
        "    yc=model(x)\n",
        "    perturbation=fgsm(epsilon,i)\n",
        "    print(\"perturbation shape \",perturbation.shape)\n",
        "    print(\"x\",x.shape)\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xp=np.squeeze(perturbation)+np.squeeze(x)\n",
        "    xp=np.expand_dims(xp,axis=(0,-1))\n",
        "  \n",
        "    yp=model(xp)\n",
        "\n",
        "    if (np.argmax(yc)!=np.argmax(yp)) and (result[i] != -1):\n",
        "      testImage(np.squeeze(x),np.squeeze(xp),np.argmax(yc),np.argmax(yp))\n",
        "\n",
        "#plotShots()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "These are general results yielded for  1000  number of random permutations\n",
            "average fool rate under my assumption :  1.0 0.0\n",
            "average success for secretary chosen data :  nan nan\n",
            "average number of data chosen by secretary :  0.0 0.0\n",
            "average number of hard chosen data :  10.0 0.0\n",
            "average number of selected data :  10.0 0.0\n",
            "random choice not knowing m success rate :  0.15102974828375287\n",
            "mean HLG grouped :  273.0\n",
            "mean LLG grouped :  7693.0\n",
            "1080.0984\n",
            "1081.2346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims, where=where)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
            "  subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WieNWxX9hcjc",
        "outputId": "6821e052-657f-4c98-b3c2-891023f2c5b1"
      },
      "source": [
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "shots=100\n",
        "iter=1000\n",
        "\n",
        "\n",
        "for i in range(iter):\n",
        "  if i%100==0:\n",
        "    print(i)\n",
        "    \n",
        "  generate_stream_data(True)\n",
        "  onlineAttack()\n",
        "  plot()\n",
        "\n",
        "\n",
        "generate_stream_data(True)\n",
        "\n",
        "fr=np.asarray(fr, dtype=np.float32)\n",
        "secretary_success=np.asarray(secretary_success, dtype=np.float32)\n",
        "\n",
        "secretary_chosen=np.asarray(secretary_chosen, dtype=np.float32)\n",
        "hard_chosen=np.asarray(hard_chosen, dtype=np.float32)\n",
        "\n",
        "print(\"These are general results yielded for \",iter,\" number of random permutations\")\n",
        "print(\"average fool rate under my assumption : \",np.mean(fr),np.std(fr))\n",
        "\n",
        "print(\"average success for secretary chosen data : \",np.mean(secretary_success),np.std(secretary_success))\n",
        "print(\"average number of data chosen by secretary : \",np.mean(secretary_chosen),np.std(secretary_chosen))\n",
        "print(\"average number of hard chosen data : \",np.mean(hard_chosen),np.std(hard_chosen))\n",
        "print(\"average number of selected data : \",np.mean(hard_chosen+secretary_chosen),np.std(hard_chosen+secretary_chosen))\n",
        "print(\"random choice not knowing m success rate : \",randomSelectionNotKnowingM())\n",
        "print(\"mean HLG grouped : \",np.mean(np.asarray(HLGRatio)))\n",
        "print(\"mean LLG grouped : \",np.mean(np.asarray(LLGRatio)))\n",
        "\n",
        "\n",
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "\n",
        "\n",
        "print(np.amax(mother_friendly_probability))\n",
        "print(np.amax(mother_initial_probability))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plotShots():\n",
        "  \n",
        "  for i in indices:\n",
        "    x= np.expand_dims(x_test[i], axis=0)\n",
        "    yc=model(x)\n",
        "    perturbation=fgsm(epsilon,i)\n",
        "    print(\"perturbation shape \",perturbation.shape)\n",
        "    print(\"x\",x.shape)\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xp=np.squeeze(perturbation)+np.squeeze(x)\n",
        "    xp=np.expand_dims(xp,axis=(0,-1))\n",
        "  \n",
        "    yp=model(xp)\n",
        "\n",
        "    if (np.argmax(yc)!=np.argmax(yp)) and (result[i] != -1):\n",
        "      testImage(np.squeeze(x),np.squeeze(xp),np.argmax(yc),np.argmax(yp))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "These are general results yielded for  1000  number of random permutations\n",
            "average fool rate under my assumption :  0.99651 0.006125344\n",
            "average success for secretary chosen data :  0.991906 0.014211816\n",
            "average number of data chosen by secretary :  41.31 5.9704185\n",
            "average number of hard chosen data :  58.69 5.9704185\n",
            "average number of selected data :  100.0 0.0\n",
            "random choice not knowing m success rate :  0.15102974828375287\n",
            "mean HLG grouped :  273.0\n",
            "mean LLG grouped :  7693.0\n",
            "1080.0984\n",
            "1081.2346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mKbmhyvhcqP",
        "outputId": "037e3508-91af-450f-d91c-95cdbec341f3"
      },
      "source": [
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "shots=1000\n",
        "iter=1000\n",
        "\n",
        "\n",
        "for i in range(iter):\n",
        "  if i%100==0:\n",
        "    print(i)\n",
        "    \n",
        "  generate_stream_data(True)\n",
        "  onlineAttack()\n",
        "  plot()\n",
        "\n",
        "\n",
        "generate_stream_data(True)\n",
        "# onlineAttack(True)\n",
        "\n",
        "fr=np.asarray(fr, dtype=np.float32)\n",
        "secretary_success=np.asarray(secretary_success, dtype=np.float32)\n",
        "\n",
        "secretary_chosen=np.asarray(secretary_chosen, dtype=np.float32)\n",
        "hard_chosen=np.asarray(hard_chosen, dtype=np.float32)\n",
        "\n",
        "print(\"These are general results yielded for \",iter,\" number of random permutations\")\n",
        "print(\"average fool rate under my assumption : \",np.mean(fr),np.std(fr))\n",
        "\n",
        "print(\"average success for secretary chosen data : \",np.mean(secretary_success),np.std(secretary_success))\n",
        "print(\"average number of data chosen by secretary : \",np.mean(secretary_chosen),np.std(secretary_chosen))\n",
        "print(\"average number of hard chosen data : \",np.mean(hard_chosen),np.std(hard_chosen))\n",
        "print(\"average number of selected data : \",np.mean(hard_chosen+secretary_chosen),np.std(hard_chosen+secretary_chosen))\n",
        "#print(\"random MLG success rate : \",randomSelectionInMLG())\n",
        "print(\"random choice not knowing m success rate : \",randomSelectionNotKnowingM())\n",
        "print(\"mean HLG grouped : \",np.mean(np.asarray(HLGRatio)))\n",
        "print(\"mean LLG grouped : \",np.mean(np.asarray(LLGRatio)))\n",
        "\n",
        "\n",
        "hard_chosen=[]\n",
        "secretary_chosen=[]\n",
        "\n",
        "secretary_success=[]\n",
        "fr=[]\n",
        "\n",
        "\n",
        "print(np.amax(mother_friendly_probability))\n",
        "print(np.amax(mother_initial_probability))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plotShots():\n",
        "  \n",
        "  for i in indices:\n",
        "    x= np.expand_dims(x_test[i], axis=0)\n",
        "    yc=model(x)\n",
        "    perturbation=fgsm(epsilon,i)\n",
        "    print(\"perturbation shape \",perturbation.shape)\n",
        "    print(\"x\",x.shape)\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xp=np.squeeze(perturbation)+np.squeeze(x)\n",
        "    xp=np.expand_dims(xp,axis=(0,-1))\n",
        "  \n",
        "    yp=model(xp)\n",
        "\n",
        "    if (np.argmax(yc)!=np.argmax(yp)) and (result[i] != -1):\n",
        "      testImage(np.squeeze(x),np.squeeze(xp),np.argmax(yc),np.argmax(yp))\n",
        "\n",
        "#plotShots()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "These are general results yielded for  1000  number of random permutations\n",
            "average fool rate under my assumption :  0.950446 0.025186725\n",
            "average success for secretary chosen data :  0.93521214 0.0064570783\n",
            "average number of data chosen by secretary :  741.789 27.86802\n",
            "average number of hard chosen data :  256.718 5.5550404\n",
            "average number of selected data :  998.507 26.403603\n",
            "random choice not knowing m success rate :  0.15102974828375287\n",
            "mean HLG grouped :  273.0\n",
            "mean LLG grouped :  7693.0\n",
            "1080.0984\n",
            "1081.2346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TESTING alpha sensitivity\n",
        "\n",
        "alpha_array=[1/4*np.exp(-2),1/3*np.exp(-2),1/2*np.exp(-2),np.exp(-2),2*np.exp(-2),3*np.exp(-2),4*np.exp(-2)]\n",
        "shots=1000\n",
        "iter=1000\n",
        "\n",
        "frs=[]\n",
        "secsucs=[]\n",
        "sec_chosens=[]\n",
        "hard_chosens=[]\n",
        "\n",
        "for alpha_value in alpha_array:\n",
        "\n",
        "  alpha=alpha_value\n",
        "  hard_chosen=[]\n",
        "  secretary_chosen=[]\n",
        "  secretary_success=[]\n",
        "  fr=[]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(iter):\n",
        "    if i%100==0:\n",
        "      print(i)\n",
        "      \n",
        "    generate_stream_data(True)\n",
        "    onlineAttack()\n",
        "    plot()\n",
        "\n",
        "\n",
        "  generate_stream_data(True)\n",
        "  # onlineAttack(True)\n",
        "\n",
        "  fr=np.asarray(fr, dtype=np.float32)\n",
        "  secretary_success=np.asarray(secretary_success, dtype=np.float32)\n",
        "\n",
        "  secretary_chosen=np.asarray(secretary_chosen, dtype=np.float32)\n",
        "  hard_chosen=np.asarray(hard_chosen, dtype=np.float32)\n",
        "  \n",
        "  sec_chosens.append(np.mean(secretary_chosen))\n",
        "  hard_chosens.append(np.mean(hard_chosen))\n",
        "\n",
        "  frs.append(fr)\n",
        "  secsucs.append(secretary_success)\n",
        "\n",
        "\n",
        "for i in range(len(alpha_array)):\n",
        "  print(\"i=\",i,\"alpha=\",alpha_array[i],\"fool rate=\",np.mean(frs[i]),\"secretary success=\",np.mean(secsucs[i]),\"#sec_chosen=\",secretary_chosen[i],\"#hard_chosens=\",hard_chosens[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plotShots():\n",
        "  \n",
        "  for i in indices:\n",
        "    x= np.expand_dims(x_test[i], axis=0)\n",
        "    yc=model(x)\n",
        "    perturbation=fgsm(epsilon,i)\n",
        "    print(\"perturbation shape \",perturbation.shape)\n",
        "    print(\"x\",x.shape)\n",
        "    perturbation=np.expand_dims(perturbation,axis=(0,-1))\n",
        "    xp=np.squeeze(perturbation)+np.squeeze(x)\n",
        "    xp=np.expand_dims(xp,axis=(0,-1))\n",
        "  \n",
        "    yp=model(xp)\n",
        "\n",
        "    if (np.argmax(yc)!=np.argmax(yp)) and (result[i] != -1):\n",
        "      testImage(np.squeeze(x),np.squeeze(xp),np.argmax(yc),np.argmax(yp))\n",
        "\n",
        "#plotShots()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl7Ls6HbAQ3u",
        "outputId": "87a663f2-0b94-4e8f-9c7d-2ff26fe90203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "i= 0 alpha= 0.033833820809153176 fool rate= 0.943795 secretary success= 0.9308649 #sec_chosen= 427.0 #hard_chosens= 196.488\n",
            "i= 1 alpha= 0.045111761078870896 fool rate= 0.94270396 secretary success= 0.92869765 #sec_chosen= 448.0 #hard_chosens= 198.267\n",
            "i= 2 alpha= 0.06766764161830635 fool rate= 0.94064504 secretary success= 0.9273352 #sec_chosen= 456.0 #hard_chosens= 202.643\n",
            "i= 3 alpha= 0.1353352832366127 fool rate= 0.94208395 secretary success= 0.9273743 #sec_chosen= 434.0 #hard_chosens= 218.268\n",
            "i= 4 alpha= 0.2706705664732254 fool rate= 0.94975704 secretary success= 0.93479514 #sec_chosen= 468.0 #hard_chosens= 256.675\n",
            "i= 5 alpha= 0.4060058497098381 fool rate= 0.862441 secretary success= 0.9418781 #sec_chosen= 417.0 #hard_chosens= 272.827\n",
            "i= 6 alpha= 0.5413411329464508 fool rate= 0.71132106 secretary success= 0.9480836 #sec_chosen= 484.0 #hard_chosens= 272.523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1=np.mean(np.asarray(frs),axis=1)\n",
        "# b1=np.arange(len(alpha_array))\n",
        "b1=np.asarray(alpha_array)/np.exp(-2)\n",
        "\n",
        "# plt.plot(b1, a1, 'xb-')\n",
        "plt.scatter(b1,a1,color='r',zorder=1)\n",
        "plt.plot(b1,a1,color='b',zorder=2)\n",
        "\n",
        "plt.xlabel('Stopping index divided by alpha',fontsize=16)\n",
        "plt.ylabel('Average fool rate %',fontsize=16)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(len(frs),len(alpha_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "aZPc62B-EzqE",
        "outputId": "43659577-7cf9-4c77-be41-212daac56c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 7\n"
          ]
        }
      ]
    }
  ]
}